---
title: "Neural Network with Keras in R"
author: "Dwi Gustin Nurdialit"
date: "`r format(Sys.Date(), '%B %e, %Y')`"
output:
  html_document:
    number_sections: true
    df_print: paged
    highlight: tango
    theme: cosmo
    toc: yes
    toc_depth: 4
    toc_float:
      collapsed: true
  pdf_document:
    toc: yes
  word_document:
    toc: yes
editor_options: 
  chunk_output_type: inline
---

<style>

body {
text-align: justify}

</style>

```{r setup, include=FALSE}
# clear-up the environment
rm(list = ls())

# chunk options
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  fig.align = "center",
  comment = "#>"
)

options(scipen = 999)
```

<style>

body {
text-align: justify}

</style>

install.packages("tensorflow")
tensorflow::install_tensorflow(version = "2.0.0")
tensorflow::tf_config()



Berikut adalah revisi agar lebih ramah untuk pemula, lebih menarik, dan dilengkapi dengan emoji untuk menambah kesan visual:

---

# ğŸ“š Neural Network dengan Keras


> **Apa itu Keras?**  
Keras adalah package yang memudahkan kita mengimplementasikan model Deep Learning. Ia bekerja di atas **TensorFlow**, sebuah framework open-source yang dikembangkan oleh Google. Di R, Keras dan TensorFlow berfungsi sebagai penghubung (mediator), sedangkan proses utama tetap dilakukan di Python. ğŸ

Mari kita uji apakah Keras sudah terhubung dengan benar dengan menjalankan kode berikut:

```{r}
library(keras)
library(dplyr)

# Membuat model sederhana
p <- keras_model_sequential(name = "Model Pertama") %>% 
  
  # ğŸ”¹ Hidden Layer Pertama
  layer_dense(units = 3, 
              input_shape = 3, 
              activation = "sigmoid", 
              name = "Hidden_layer") %>% 
  
  # ğŸ”¹ Output Layer
  layer_dense(units = 2, activation = "sigmoid", name = "Output")

p
```

Jika berhasil, akan muncul informasi modelnya. ğŸ‰ Ini menandakan Keras sudah siap digunakan!


# ğŸ–¼ï¸ Dataset MNIST

Kita akan menggunakan **MNIST**, dataset berisi ribuan gambar digit angka hasil tulisan tangan. ğŸ¨ Tugas kita adalah membuat model Machine Learning untuk mengenali angka **0 sampai 9**. 

ğŸ’¡ **Gambaran Dataset**: 

- **Target Variabel (`label`)**: Digit angka yang harus dikenali (misal: 0, 1, 2).  
- **Pixel Grayscale**: Nilai kecerahan tiap pixel pada gambar hitam putih.

Berikut contoh tampilan dataset MNIST:

```{r echo=FALSE, out.width="80%" }
knitr::include_graphics("asset/mnist.png")
```

## 1ï¸âƒ£ Memuat Data

Pertama-tama, mari kita muat dataset-nya. MNIST sudah dibagi menjadi data latih (train) dan uji (test), jadi kita tidak perlu melakukan cross-validation manual.

```{r}
# Memuat data
train_mnist <- 
test_mnist <- 

# Melihat dimensi data

```


## 2ï¸âƒ£ Exploratory Data

Mari lihat beberapa baris pertama dari data latih untuk memahami formatnya:

```{r}

```




### ğŸ–ï¸ Visualisasi Gambar

Setiap gambar direpresentasikan dalam ukuran **28 x 28** pixel. Untuk memudahkan, kita akan mengubah nilai pixel menjadi gambar visual menggunakan fungsi berikut:

```{r}
vizTrain <- function(input){
  dimmax <- sqrt(ncol(input[,-1]))
  dimn <- ceiling(sqrt(nrow(input)))
  par(mfrow = c(dimn, dimn), mar = c(.1, .1, .1, .1))
  
  for (i in 1:nrow(input)){
    m1 <- as.matrix(input[i, 2:785])
    dim(m1) <- c(28, 28)
    m1 <- apply(apply(m1, 1, rev), 1, t)
    
    image(1:28, 1:28, 
          m1, col = grey.colors(255), 
          xaxt = 'n', yaxt = 'n') # Hilangkan sumbu
    text(2, 20, col = "white", cex = 1.2, input[i, 1]) # Tambah label angka
  }
}
```

Mari kita coba menampilkan **36 gambar pertama** dari dataset latih:

```{r}
vizTrain(head(train_mnist, 36))
```








## 3ï¸âƒ£ Cross-Validation

Untuk memvalidasi model, kita perlu membagi data menjadi **data latih (train)** dan **data validasi (validation)**. ğŸ’¡ 

- **80%** data akan digunakan sebagai data latih.  
- Data validasi akan membantu kita menguji performa model selama proses pelatihan.  
- Data uji (`test.csv`) hanya digunakan untuk kompetisi di [Kaggle](https://www.kaggle.com/c/digit-recognizer) karena tidak memiliki label.

Mari kita bagi data menggunakan `rsample`:

```{r}
library(rsample)

# Membagi data menjadi train dan validation
set.seed(100)
index <- 

data_train <- 
data_test <- 
```

Untuk memastikan proporsi kelas target tetap terjaga, kita cek distribusi kelas pada data latih:

```{r}
# Cek proporsi kelas

```


## ï¸4ï¸âƒ£ Data Preprocessing

Sebelum membuat model dengan **Keras**, kita perlu mempersiapkan data. Ini langkah-langkah yang dilakukan:

1. **Pisahkan target variabel (`label`) dari prediktor**.  
2. **Ubah prediktor menjadi matriks/array** untuk mempermudah komputasi.  
3. **Scaling nilai pixel (0-255) menjadi rentang 0-1**.  
4. **One-hot encoding** target variabel karena model memerlukan representasi numerik biner.

### 1. Scaling Data

Karena nilai pixel gambar berada pada rentang 0-255, kita akan membagi nilai tersebut dengan 255 untuk merubah rentangnya menjadi **0-1**.

```{r}
library(dplyr)

# Pisahkan data latih
train_x <- 

train_y <- 

# Pisahkan data validasi
test_x <- 

test_y <- 
```

ğŸ‘‰ **Catatan**: Scaling sangat penting untuk mempercepat konvergensi model deep learning!

Cek apakah scaling bekerja dengan benar:

```{r}
range(data_train$pixel400)/255
```

### 2. Reshaping Data

Format data harus diubah ke array agar dapat diterima oleh Keras. Kita gunakan fungsi `array_reshape(x, dim)`:

```{r}
library(keras)

# Ubah format ke array
train_x <- 
test_x <- 
```

### 3. One-Hot Encoding

Target variabel (`label`) berupa angka **0-9** perlu diubah menjadi format **one-hot encoding**. Ini dilakukan menggunakan fungsi `to_categorical(data, num_classes)` dari Keras.

```{r}
# One-hot encoding untuk target variabel
train_y <- 
test_y <- 
```











## ğŸ—ï¸ Arsitektur Neural Network

Sekarang, kita akan membangun arsitektur **Neural Network**! ğŸ‰  
Berikut adalah **aturan dasar** saat membuat arsitektur di Keras:

1. Mulai dengan `keras_model_sequential()` untuk mendefinisikan model.  
2. Layer pertama yang dibuat menjadi **input layer** secara otomatis.  
3. Tambahkan **parameter `input_shape`** pada layer pertama untuk menentukan dimensi input.  
4. Layer terakhir yang dibuat menjadi **output layer**.

### ğŸ”¢ Menentukan Dimensi Input dan Output

Pertama, mari tentukan dimensi input (jumlah prediktor) dan jumlah kategori target (jumlah kelas 0-9):

```{r}
input_dim <- ncol(train_x)          # Jumlah prediktor (784 pixel)
num_class <- n_distinct(data_train$label) # Jumlah kelas target (0-9)
```


### ğŸ’¡ Desain Arsitektur Neural Network

Kita akan membangun model dengan spesifikasi berikut:  
- **Input Layer**: ... neuron (untuk 28x28 pixel).  
- **Hidden Layer 1**: ... neuron dengan activation function **ReLU**.  
- **Hidden Layer 2**: ... neuron dengan activation function **ReLU**.  
- **Output Layer**: ... neuron (jumlah kelas 0-9) dengan activation function **Softmax**.  


## 5ï¸âƒ£ Membangun Model

Mari kita buat model Neural Network dengan menggunakan `keras_model_sequential()`:

```{r}
library(keras)

# Membuat arsitektur Neural Network
model1 <- 
```

ğŸ“Œ **Keterangan**:  

- **Total params**: Jumlah total parameter (bobot + bias) dalam model.  
- **Trainable params**: Parameter yang dapat diperbarui selama pelatihan.  
- **Non-trainable params**: Parameter yang terkunci dan tidak diperbarui.  



## ğŸ”§ Model Compile

Sebelum melatih model, kita perlu menentukan:  
1. **Error Function** (*Loss Function*): Mengukur seberapa baik model memprediksi data.  

   - **Regresi**: `MSE`, `MAE`, dll.  
   - **Klasifikasi Biner**: `Binary Cross-Entropy`.  
   - **Klasifikasi Multikelas**: `Categorical Cross-Entropy`.  

2. **Optimizer**: Mengatur cara model memperbarui bobot selama pelatihan.  

   - Contoh: `SGD`, `Adam`.  

3. **Metrics**: Metode evaluasi performa model selama pelatihan (misalnya `accuracy`).  

ğŸ’¡ Referensi: [Loss Function](https://keras.rstudio.com/reference/loss_mean_squared_error.html), [Optimizer](https://keras.rstudio.com/reference/index.html#section-optimizers)


## 6ï¸âƒ£ Meng-Compile Model

Kita gunakan **Categorical Cross-Entropy** sebagai *loss function*, **SGD** sebagai optimizer, dan evaluasi dengan **accuracy**.

```{r}
# Compile model
model1
```



## ğŸ‹ Model Fitting

Tahap berikutnya adalah melatih model Neural Network kita menggunakan data training! Pada tahap ini, model akan:

1. **Feed Forward**: Menghitung prediksi berdasarkan data input.  
2. **Back Propagation**: Memperbarui bobot model berdasarkan kesalahan prediksi (error).  

### ğŸ§© Apa Itu Batch dan Epoch?

- **Batch Size**: Jumlah data yang diproses model sebelum memperbarui bobot.  
- **Epoch**: Ketika model telah memproses seluruh data training satu kali penuh (termasuk semua batch).  

Contoh:  

Jika data training terdiri dari 33,600 baris dan **batch size = 4,200**, maka:  
\[
\text{Jumlah batch} = \frac{\text{Jumlah data}}{\text{Batch size}} = \frac{33600}{4200} = 8
\]  
Dalam 1 epoch, model akan melakukan feed forward dan back propagation sebanyak 8 kali.  


ğŸ“Š **Karakteristik Batch Size**:

- **Batch size kecil**: Pelatihan lebih lama, tetapi cenderung memberikan hasil yang lebih baik.  
- **Batch size besar**: Pelatihan lebih cepat, tetapi dapat kehilangan detail dalam pembelajaran.


## 7ï¸âƒ£ Melatih Model

Saat melatih model, berikut parameter yang perlu disiapkan:

- `x`: Prediktor (data input).  
- `y`: Target variabel (label).  
- `epochs`: Jumlah iterasi untuk pelatihan.  
- `batch_size`: Jumlah data dalam satu batch.  
- `validation_data`: Data validasi untuk mengevaluasi model selama pelatihan.  
- `verbose`: Apakah ingin menampilkan progres pelatihan secara visual.  

Kita akan melatih model selama **10 epoch** dengan **batch size = 4200**. Berikut adalah kode untuk melatih model:

```{r}
# Melatih model
history <- 

# Visualisasi performa model

```



## 8ï¸âƒ£ Model Evaluation

Setelah model dilatih, mari evaluasi performanya menggunakan data validasi! ğŸ¯  

1. **Prediksi Data Validasi**  
   Model akan memberikan probabilitas untuk setiap kelas. Kita ambil kelas dengan probabilitas tertinggi menggunakan `k_argmax()`.

```{r}
# Prediksi data validasi
pred <- 
```

2. Evaluasi dengan Confusion Matrix

   Gunakan `confusionMatrix` dari paket `caret` untuk melihat akurasi model.

```{r}
# Evaluasi performa dengan Confusion Matrix
library(caret)
confusionMatrix(data = pred, reference = as.factor(data_test$label))
```


## ğŸ”„ Summary Workflow

Berikut langkah-langkah untuk membangun Neural Network dengan Keras:  

1. **Bangun Arsitektur Model**:  

   - Tentukan jumlah hidden layer dan neuron.  
   - Pilih jenis activation function (contoh: ReLU, Sigmoid).  

2. **Compile Model**:  

   - Pilih error function (contoh: Cross-Entropy).  
   - Pilih optimizer dan learning rate.  

3. **Training Model**: 

   - Tentukan batch size dan jumlah epoch.  
   - Gunakan data validasi untuk melihat performa selama pelatihan.  



## ğŸš€ Model Improvement

Jika hasil model belum memuaskan, kita bisa mencoba **tuning hyperparameter** untuk meningkatkan performa. ğŸ”§  

ğŸ”‘ **Hyperparameter yang Bisa Dicoba**:

1. **Activation Function**: Ganti ReLU dengan fungsi lain (contoh: Leaky ReLU, Tanh).  
2. **Jumlah Neuron**: Tambah atau kurangi neuron di hidden layer.  
3. **Jumlah Layer**: Tambahkan layer untuk menangkap lebih banyak informasi.  
4. **Optimizer**: Ganti dari `SGD` ke `Adam` atau yang lain.  
5. **Learning Rate**: Coba berbagai nilai, misalnya 0.01, 0.001.  




## Tuning 1

Kita coba ubah jumlah unit pada tiap layer dengan ketentuan sebagai berikut:

- Input layer: 784 prediktor (gambar 28x28 pixel)
- Hidden Layer 1: 128 neuron dengan activation function = relu
- Hidden Layer 2: 32 neuron dengan activation function = relu
- Output Layer: 10 neuron (sesuai jumlah kategori 0-9) dengan activation function = softmax

```{r}
model_tuning1 <- 
```

```{r}

```


## Tuning 2

Kita coba tambah jumlah hidden layer dengan ketentuan sebagai berikut:

- Input layer: 784 prediktor (gambar 28x28 pixel)
- Hidden Layer 1: 128 neuron dengan activation function = relu
- Hidden Layer 2: 32 neuron dengan activation function = relu
- Hidden Layer 3: 16 neuron dengan activation function = relu
- Output Layer: 10 neuron (sesuai jumlah kategori 0-9) dengan activation function = softmax

```{r}
model_tuning2 <- 


```


___________________________________________


## ğŸ„ Dive Deeper

Lakukan tuning terhadap model dengan mengganti jumlah layer, jumlah node/neuron maupun mengganti parameter lain yang ada di model sehingga mendapatkan akurasi yang lebih tinggi dibandingkan model yang sudah dibuat.

___________________________________________

## Tuning 3

Kita coba ubah optimizernya dari `sgd` menjadi `adam`

```{r}
set.seed(100)
model_tuning3 <- 
```

> 

## ğŸ“¥ Save & Load Model

ini sama seperti save model pada rds

```{r eval=FALSE}
# save

```

```{r eval = F}
# load model

```

```{r eval = F}
# cek model

```
  

# Additional Link & References

[Deep Learning Tips and Tricks cheatsheet, By Afshine Amidi and Shervine Amidi, Stanford Edu](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks)

[11 Essential Neural Network Architectures, Visualized & Explained](https://medium.com/analytics-vidhya/11-essential-neural-network-architectures-visualized-explained-7fc7da3486d8)

[Various cases on Deep Learning at algotech.netlify.app](https://algotech.netlify.app/tags/deep-learning/)

[Image Classification using CNN](https://algotech.netlify.app/blog/image-classification-cnn/)
